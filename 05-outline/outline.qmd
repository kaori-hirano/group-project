---
title: "Extended Outline"
author: "Group 4: Kaori Hirano, Alicia Nguyen, James Xia"
date: "07/27/23"
format: pdf
execute: 
  error: true
  message: false
  warning: false
  eval: true
---
```{r load-packages, echo = FALSE}
library(readr)
library(readxl)
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(dplyr))
library(patchwork)
suppressPackageStartupMessages(library(glmnet)) # for ridge, LASSO
suppressPackageStartupMessages(library(randomForest))
suppressPackageStartupMessages(library(caret))
library(Matrix)
library(broom)
library(tree)
library(tibble)
```

# Introduction and Data
## Topic & Research Question
The introduction provides motivation and context for your research. Describe your topic (citing sources) and provide a concise, clear statement of your research question and expectations.

## Data
Then identify the source of the data, when and how it was collected, the cases, a general description of relevant variables. You should describe any data wrangling that you have done, any variables you have changed from the original data set, the data tidying you had to do, and what variables you plan to include in any models you will do, and why.
```{r introduction to data/merge data}
wh_2023 <- read_excel("/cloud/project/data/wh_2023.xls")
load("/cloud/project/data/vdemdata-master/data/vdem.RData")
## load the original datasets

need_vdem=c("country_name","year","v2csreprss",'e_civil_war',"e_pt_coup",
"v2x_partipdem","e_peaveduc","v2x_corr","v2x_cspart","v2xcs_ccsi", 'e_regionpol')
vdem_use=vdem[,need_vdem]
need_wh=c("Country name","year","Social support","Freedom to make life choices","Generosity","Life Ladder","Healthy life expectancy at birth","Log GDP per capita")
wh_use=wh_2023[,need_wh]
## only select the portions where we need to need for our project

colnames(wh_use)[1] <- "country_name"
## change col name for eaier merge

total=merge(vdem_use, wh_use, by = c("country_name", "year"),
            all.x=TRUE,
            all.y=TRUE) 
##merge data
```
 
  In this part, nearly all variables in wh_2023 are selected because we do not have sufficient background to interpret necessary relationships. We do the same for vdem_use dataset. However, incorporating all datasets is not possible. Thus, we incorporate all the quantified data variables associated with political events and possible social activities. Thus the final incorporated is a comprehensive dataset based on full analyses of given codebooks.  
  
```{r clean data}
#| message: false
#| warning: false

# Select the time range from 2012 (inclusive) and later only 
total_2012 <- total[total$year > 2011,]
head(total_2012) 

# changing the NA entries with a median of that column
summary(total_2012)
total_not_NA <- total_2012 %>% na.omit() 
total_2012 %>% group_by(e_civil_war) %>% count()

#replace missing values in each numeric column with median value of column
new_total <- total_2012 %>% mutate(across(where(is.numeric),~replace_na(.,median(.,na.rm=TRUE))))

# changes names to shorter and easier to type/remember forms
```
For the sake of completeness of the data, no additional changes are made. For further analysis, the NA data are omitted. 
```{r final change to data}
cs <- new_total %>% rename(csrepress = v2csreprss, civil_war = e_civil_war, coup = e_pt_coup,
                           edu = e_peaveduc, corr = v2x_corr, cspart = v2x_cspart, 
                           cs_index = v2xcs_ccsi, social_support = 'Social support', 
                           choices = 'Freedom to make life choices', gen = Generosity,
                           region = e_regionpol,
                           # CHECK THIS VARIABLE DESCRIPTION AGAIN
                           happ = "Life Ladder", 
                           lifee = "Healthy life expectancy at birth", 
                           gdp = "Log GDP per capita")

cs <- cs %>% filter(year > 2011) # updates to match year for both datasets 
# the full measures for happiness start in 2012, so all years before then are 
# filtered out for the sake of analysis
cs$region <- as.factor(cs$region)
#saveRDS(cs, file = "civil_society")
```
  The names of used variables are shortened for further analysis. The year 2019 is chosen as our focus specifically because we want to focus on the change before and after pandemic year. 2019 is the most recent data set we have that is not reflecting social changes due to COVID-19. This might be more representative of the social conditions before the pandemic year and thus help us answer our main research question of how civil participation has changed before and after the pandemic. 
  
The introduction provides motivation and context for your research. Describe your topic (citing sources) and provide a concise, clear statement of your research question and expectations.

Then identify the source of the data, when and how it was collected, the cases, a general description of relevant variables. You should describe any data wrangling that you have done, any variables you have changed from the original data set, the data tidying you had to do, and what variables you plan to include in any models you will do, and why.

# Methodology
The methodology section should include visualizations and summary statistics relevant to your research question. You should also justify the choice of method(s) used to answer your research question.

note: when editing data, we should rename the region levels to the actual regions they represent. also, if we add more variables from happiness as suggested, we'll need to update the codebook

note: do a visualization between region and social support, as well as one between civil society participation and participation in democracy? or even civil society index as well. actually region and like as many things as possible would be great - must understand the similarities between regions in the results so any way to compare the means of them in various important predictors or like any predictors would be swell

```{r data}
#| warning: false 
cs_full <- readRDS("/cloud/project/data/civil_society")
names(cs_full)
# get only 2019 and remove civil war and coup because there are none in 2019
cs <- cs_full %>% subset(year == 2019) %>% select(-one_of("civil_war", 
                                                          "coup")) %>% drop_na()

# looks for region with most observations to set as base level table(cs$region)
cs$region <- relevel(cs$region, ref = 4)
# Sub Saharan Africa, was used as baseline because it has the most observations
# NEED TO EXPLAIN WHY THE REGION WITH MOST OBS CAN BE USED AS REF BASE

# creates new data frame for tree plotting with regions as numbers still
cs_num <- cs

# recodes region to be the region it represents rather than a number value/code
levels(cs$region) <- c('SubSaharanAfrica',
                    'EasternEurope_PostSovietUnion', 
                    'LatinAmerica',
                    'NorthAfrica_MiddleEast',
                    'WesternEurope_NorthAmerica',
                    'EasternAsia',
                    'SouthEasternAsia',
                    'SouthernAsia',
                    'ThePacific',
                    'TheCarribean')

names(cs)
```

```{r variable-summary}
#| warning: false
#| message: false

summary(cs)

```
We can see that the scale of the variables used as predictors vary widely. This is why it is ideal to scale the data while doing Lasso and Ridge regression. We do not have to scale data in random Forest model. 

Our research question is whether region, ... (ADD VARIABLE) would be important in predicting civil society participation across countries. Our outcome variable is a numerical variable. Therefore, we chose regression models: Lasso and Ridge to help us eliminate unimportant variables. We also used random Forest to help us see the ranking of the relative importance of the predictor variables in our model. If the top most important variables produced by our machine learning models are consistent with our hypothesis, and the model works well when applied to the test set, this means that the model results are relatively consistent with our hypothesis. We also want to see the specific relationship, negative or positive, and the magnitude of the relationship between our outcome variable and each of the predictor variable to help shed light on our research question. 

```{r variable-visualization}
#| warning: false
#| message: false

# A scatter plot to show the relationship between civil society participation 
# and social support
ggplot(cs, aes(x=social_support, 
               y = v2x_partipdem)) + 
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Social support",
       y = "Participation in democracy",
title = "Relationship between Participation in Civil society and Social Support",
color = "Regions")

# A scatterplot to show the relationship between civil society participation 
# and participation in democracy
ggplot(cs, aes(x=cspart, 
               y = v2x_partipdem)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Civil society participation",
       y = "Participation in democracy",
title = "Relationship between Participation in Civil society and in democracy")

# A scatterplot to show the relationship between civil society participation 
# and civil society index
ggplot(cs, aes(x=cs_index, 
               y = cspart)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Civil society index",
       y = "Civil society participation",
       title = "Relationship between Civil Society Participation and Index")

# A box plot to show the relationship between region and 
# Civil Society Participation
ggplot(cs, aes(x=as.factor(region), 
               y = cspart, 
               color = as.factor(region),
               group = as.factor(region))) + 
  geom_boxplot() + 
  labs(x = "Regions",
       y = "Civil society participation by region",
       title = "Civil society participation levels within different regions",
       color = "Regions") + 
  # Rotate x-axis labels by 90 degrees to the left
  theme(axis.text.x = element_text(angle = 45, hjust = 0.9))

# A box plot to show the relationship between region and social support
ggplot(cs, aes(x=as.factor(region), 
               y = social_support, 
               color = as.factor(region),
               group = as.factor(region))) + 
  geom_boxplot() + 
  labs(x = "Regions",
       y = str_wrap("Social support by region",
       width = 30),
       title = "Social support levels within different regions",
       color = "Regions") + 
  # Rotate x-axis labels by 90 degrees to the left
  theme(axis.text.x = element_text(angle = 45, hjust = 0.9))

# A box plot to show the relationship between region and Civil Society Index
ggplot(cs, aes(x=as.factor(region), 
               y = cs_index, 
               color = as.factor(region),
               group = as.factor(region))) + 
  geom_boxplot() + 
  labs(x = "Regions",
       y = "Civil Society Index by region",
       title = "Civil Society index within different regions",
       color = "Regions") + 
  # Rotate x-axis labels by 90 degrees to the left
  theme(axis.text.x = element_text(angle = 45, hjust = 0.9))

# A box plot to show the relationship between region
# and participation in democracy
ggplot(cs, aes(x = as.factor(region), 
               y = v2x_partipdem, 
               color = as.factor(region),
               group = as.factor(region))) + 
  geom_boxplot() + 
  labs(x = "Regions",
       y = "Participation in Democracy by region",
       title = "Participation in Democracy within different regions",
       color = "Regions") + 
  # Rotate x-axis labels by 90 degrees to the left
  theme(axis.text.x = element_text(angle = 45, hjust = 0.9))

```
# Results
Showcase how you arrived at answers to your research question using the techniques we have learned in class (and beyond, if you’re feeling adventurous).

Provide only the main results from your analysis. As a reminder, the goal is not to do an exhaustive data analysis (calculate every possible statistic and perform every possible procedure for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in interpreting and presenting results, and that you can accomplish these tasks using R. More is not always better.

# what does 'main results' mean? like don't include the output? or how we got there? or only the important output?

```{r test-train-split}
# 70, 30 test train split
set.seed(145)
train <- sample(c(TRUE, FALSE), nrow(cs), replace = TRUE, prob=c(.7,.3))
test <- (!train)
val <- test
```
   
```{r matrix-creation}
# create x and y for glmnet
set.seed(129)
x <- model.matrix(cspart ~ csrepress+v2x_partipdem+edu+corr+cs_index+
                           social_support+choices+gen+region+lifee+happ+gdp, 
                  data = cs)[, -1]
y <- cs$cspart
```

```{r ridge-regression}
# set seed for reproducibility
set.seed(129)

# cross validation for best l
cv_r <- cv.glmnet(x[train,], y[train], alpha = 0, 
                  lambda = 10^seq(10, -2, length = 100))

# saving optimal lambda
bestlam_r <- cv_r$lambda.min

# calculating MSE
ridge_pred <- predict(cv_r, s = bestlam_r,
newx = x[test, ])
ridge_mse <- mean((ridge_pred - y[test])^2)

# fits final ridge model
ridge_mod <- glmnet(x, y, alpha = 0, lambda = bestlam_r)

# saves coefficients
coef_r <-coef(ridge_mod)

# prints important coefficients as a table
ridge_feature_estimate <- ridge_mod %>% tidy() %>%
  select(term, estimate)
print(ridge_feature_estimate)
```

```{r lasso-regression}
# set seed for reproducibility
set.seed(18)
 
# cross validation for best l
cv_l <- cv.glmnet(x[train,], y[train], alpha = 1,
lambda = 10^seq(10, -2, length = 100))

# saving optimal lambda
bestlam_l <- cv_l$lambda.min

# calculating MSE
lasso_pred <- predict(cv_l, s = bestlam_l,
newx = x[test, ])
lasso_mse <- mean((lasso_pred - y[test])^2)

# fits model
lasso_mod <- glmnet(x, y, lambda = bestlam_l)

# saves coefficients
coef_l <-coef(lasso_mod)

# prints important coefficients as a table
lasso_feature_estimate <- lasso_mod %>% tidy() %>%
  select(term, estimate)
print(lasso_feature_estimate)
```

```{r plot-tree, echo=FALSE}
format_tree_labels <- function(labels, levels) {
  sapply(labels, \(x) if(grepl(":", x)) clean_col(x, levels) else clean_lt(x))
} 

# replace letter positions with actual level labels
clean_col <- function(x, levels){
  # split the label into label and levels
  x <- str_split_1(x, ":")
  # make new temp objects for the two components
  var <- x[1]
  levs_ids <- x[2]
  # get levels for correct variable
  levs <- levels[[var]]
  # get level ids for *relevant* levels
  levs_ids <- str_split_1(levs_ids, "") 
  levs_ids <- sapply(levs_ids, \(x) which(letters == x))
  # cut down levs to only the required levels
  levs <- levs[levs_ids]
  # paste everything together and return (immplicitly)
  paste0(var, ": ", paste0(levs, collapse = ", "))
}

# space out labels that include only "<"
clean_lt <- function(x){
  # split on <, then recombine with spaces before and after <
  x <- str_split_1(x, "<")
  paste0(x, collapse = " < ")
}

plot_tree <- function(model){
  require(ggdendro)
  # extract necessary information from tree object so that it is ggplotable
  tree_data <- dendro_data(model)
  # create a data frame with the split *values* which dendro_data() doesn't extract
  frame <- model$frame %>%
    rownames_to_column(var = "split") %>%
    mutate(splits = as.data.frame(splits)) %>% 
    unnest(cols = c(splits)) %>% 
    filter(var != "<leaf>") %>% 
    select(cutleft)
  
  # add the splits information in, which dendro_data() misses
  tree_data$labels <- tree_data$labels %>% 
    bind_cols(frame) %>% 
    mutate(label = paste0(as.character(label), cutleft),
           label = format_tree_labels(label, attr(model, "xlevels")))
      
  ggplot(segment(tree_data)) +
    geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) +
    geom_text(data = label(tree_data), 
              aes(x = x, y = y, label = label), vjust = -0.5, size = 3) +
    geom_text(data = leaf_label(tree_data), 
              aes(x = x, y = y, label = label), vjust = 1.5, size = 2) +
    theme_dendro()
}
```

```{r tree-method}
# sets set for reproducibility
set.seed(247) 

# creates tree on training data
tree_train <- tree(cspart ~ . -year -country_name, cs_num,
    subset = train)

# cross validation of tree
cv_train <- cv.tree(tree_train)

# pruning to 8 nodes per CV results
prune_train <- prune.tree(tree_train, best = 8)

# plots pruned tree
plot_tree(prune_train) + 
  labs(title = "Pruned Tree Plot",
       caption = 'Regions 1, 2, 3, 7, and 9 represent Eastern Europe & Post
       Soviet Union, Latin America, North Africa and Middle East, South Eastern 
       Asia, and the Pacific') + 
  # Center the plot title
  theme(plot.title = element_text(hjust = 0.4))

# gets predictions and test values for mse
tree_pred_tuned <- predict(prune_train, cs_num[test,],
    type = "vector")
y_test <- y[test]

# gets mse for pruned tree
mse <- mean((tree_pred_tuned - y_test)^2)
```

```{r random-forests}
# sets seed for reproducibility
set.seed(286)

# sets cv parameters
train_control <- trainControl(method="cv", number = 5)

# gets grid for mtry
# IS THIS MTRY RANGE GOOD
tune_grid <- expand.grid(mtry = 3:12)

# does training
best_forest <- train(cspart ~ . -year -country_name, data = cs[train,], 
                     trControl = train_control, 
                     method="rf", 
                     tuneGrid = tune_grid,
                     verbose = FALSE)
best_forest

# gets test for y
y_test <- y[test]

# predictions for test set with optimal mtry of 9
rf_cs <- randomForest(cspart ~ . -year -country_name, data = cs[train,], 
                       mtry = 9, importance = TRUE)

yhat_rf <- predict(rf_cs, newdata = cs[test,])

# calculates MSE
rf_mse <- mean((yhat_rf - y_test)^2)

# importances
importances_cs <- importance(rf_cs) %>% 
  as_tibble(rownames = "Variable")

# plot 1
p1_rf <- importances_cs %>% 
  arrange(`%IncMSE`) %>% 
  mutate(Variable = factor(Variable, levels = Variable)) %>% 
  ggplot(aes(x = `%IncMSE`, y = Variable)) +
  geom_col(alpha = 0.5) +
  labs(title = "Variable Importance Plot 1") +
  theme_classic()

# plot 2
p2_rf <- importances_cs %>% 
  arrange(IncNodePurity) %>% 
  mutate(Variable = factor(Variable, levels = Variable)) %>% 
  ggplot(aes(x = IncNodePurity, y = Variable)) +
  geom_col(alpha = 0.5) +
  labs(title = "Variable Importance Plot 2") +
  theme_classic()

# side by side
p1_rf + p2_rf

# prints table of most important variables
# feature names minus year, country, cspart
rf_feature_names <- colnames(cs[,c(3:6, 8:15)])

# importance scores
rf_importance_scores <- rf_cs$importance[, 1]

# combine feature names and importance scores
rf_feature_importance <- tibble(Feature = rf_feature_names, 
                                '% Increase MSE' = rf_importance_scores)

# Print the result
print(rf_feature_importance)
```

## Visualizing
```{r, echo = FALSE}
#| warning: false
# note: I think we are planning to cut this because
# interpretation-wise it doesn't add much that the MSE doesn't
# already cover. 

# putting together data of predicted, actual, and model type
dataplot <- data.frame(true_value = c(y[test], y[test], y[test], y[test]))
dataplot$model_type <- c(rep("Lasso", length(lasso_pred)), rep("Ridge Model", 
            length(ridge_pred)), rep("Tree Model", length(tree_pred_tuned)), 
            rep('Random Forests', length(yhat_rf)))
dataplot$predictions <- c(lasso_pred, ridge_pred, tree_pred_tuned, yhat_rf)

#plotting predicted vs actual by model type
compare <- ggplot(dataplot, aes(y = predictions, x = true_value,
                                color = model_type)) +
  geom_jitter() + geom_abline(intercept = 0, slope = 1) +
  labs(x = "Predicted Outcome", y = "Actual Outcome",
       title = 'Comparison of Model Type by Predicted vs Actual', 
       color = 'Model Type') + theme_classic() 

# function giving us R2
r2 <- function(predicted, y) {
  #find SST and SSE
  sst <- sum((y - mean(y))^2)
  sse <- sum((predicted - y)^2)
  #find R-Squared
  rsq <- 1 - sse/sst
}

# setting up values for graph
name=c("Tree","Random Forest", "LASSO","Ridge")
mse_all=c(mse, rf_mse, lasso_mse, ridge_mse)
value=c(r2(tree_pred_tuned, y[test]), r2(yhat_rf, y[test]), 
        r2(lasso_pred, y[test]), r2(ridge_pred, y[test]))

# putting into table
compare_data=tibble(name,mse_all,value)

#plotting MSE
p1=ggplot(compare_data, aes(x=name, y=value))+
  geom_col()+ coord_cartesian(ylim=c(0.8,.9))+
  labs(x="Model",y="R2",title = "Comparing R2") +
  theme_classic()

# plotting R Squared
p2=ggplot(compare_data, aes(x=name, y=mse_all))+
  geom_col()+ coord_cartesian(ylim=c(0.00,0.01))+
  labs(x="Model",y="MSE",title = "Comparing MSE") +
  theme_classic()
compare / (p1+p2)

```

# Discussion

## This section is a conclusion and discussion. This will require a summary of what you have learned about your research question along with statistical and methodological arguments supporting your conclusions. You should critique your own methods and provide suggestions for improving your analysis and future work.

Our research question regarded predictors of civil society participation. We hypothesized that countries with similar characteristics regarding social cohesion--such as region, presence of war, social support, and civil society index--will have similar civil society participation rates. The results of our data analysis partially supported our hypothesis, with the most important predictors identified being civil society index, region, and participation in democracy, which were seen across all models, and social support and civil society repression which was found by a minority of the models run. However, social support was shown to have a negative effect on civil society participation in 2019, which we did not expect. 

Civil society index and participation in democracy were the top two predictors in all models, with region, social support, and civil society repression being identified as top predictors by some of the models. Civil society index had a positive impact on civil society participation, meaning that as elements of civil society increased so as to increase the civil society index, such as increasing the number of civil society organizations, the civil society participation would also increase. This makes sense because a higher civil society index means that there are likely more and better opportunities for people to engage in civil society, therefore increasing participation. Similarly, as participation in democracy increases, so does participation in civil society. Many civil society organizations have roles in politics, so as there is more political behavior more people likely will also engage in civil society. Further study into the relationship between civil society and participation in democracy is warranted to learn more about how these two processes interact with and influence each other. 

In terms of region, countries located in the Pacific, Western Europe and North Africa and the Middle East, Latin America, Southeastern Asia, and Eastern Europe and Post Soviet Union states were all associated with a decrease in civil society participation. This result was surprising because there were no regions associated with an increase in civil society participation, leading us to think that factors within a country may be more important than region overall. (Is there a commonality between all of the negative regions? the only thing I can think of is like colonialism/imperialism but that also applies to some that aren't negative? because I don't want to make up things about these regions that I just don't know which seems to be what simon wants?) Our choice of regression and tree methods would not work as well at explaining these differences as a clustering method may have, which could have illuminated the similarities between regions with similiar civil society participation rates as well as other important factors. In terms of understanding why these regions are significant in more certain terms, further analysis, such as k-means clustering, is required. 

The other key predictors identified were civil society repression and social support, which were both associated with a negative effect on civil society participation. As measures to increase repression of civil societies increase, such as the decrease of influence of civil society organizations, a decrease in civil society participation is predicted. As opportunities to participate in civil society decrease or become more difficult to access, it would make sense that people would participate less in civil society as a whole. Surprisingly, an increase in social support is associated with a decrease in civil society participation. Social support is defined as whether someone feels they have someone to turn to in a difficult situation. We hypothesized that if countries were to have more social support, it meant they would have stronger civil society networks. However, the results suggest that having social support may indicate that people have strong social support networks already, decreasing the need to participate in civil society organizations. More research into this relationships is needed to fully understand the effects of social support on civil society participation.


## You should also discuss issues pertaining to the reliability and validity of your data and the appropriateness of the analyses should also be discussed.
reliability is consistency/reproducibility/precision of a measure, validity is accuracy of measure (how well does it match established theories) (content validitiy is adequate coverage of the subject, criterion validity is whether it performs as expected/is a meaningful parameter, construct is does it match what it should. 

Reliability is the consistency or reproducibility of the results. We did our best to make results reproducible by including set seed anytime we needed random number generation. This ensures that if someone were to replicate our project they would get the same results we did. From the provided codebooks, we can tell the methods of the data collection are consistent and reliable. For validity, the codebooks provided thorough descriptions of how the measures were calculated, what was included, and why. These variables should have high validity. As for the variables we chose, there was less validity in terms of the selected variables being good measures of civil society participation because we had minimal amounts of research when determining which variables to include in our project. This means that even though the variables measured what they claimed to, they may have had less . 
? in terms of validity, does it refer to the way we used it or just the measurement

You must include at least one paragraph discussing in what ways the training data you used limits any inferential conclusions or predictions for new data you can make.

The training data we used certainly limited our conclusions and predictions. Our data consisted of 187 observations, 70% of which were in the training set. While this is a majority of the countries of the world, it is still a limited sample. This greatly limited the generalizability of our results due to the smaller number of observations and because it removed any patterns that may have been present over time. 2019 was chosen due to a desire to understand the key factors in civil society participation as close to the present day, without the effects of covid, as possible. However, doing a comparison over time would give us more generalizability by allowing us to see if predictors continued to be important over time or not. Additionally, 2019 did not have any recorded instances of civil wars or coups, meaning we were not able to assess the influence of these predictors on civil society participation. Going over time or picking a year that included these variables would have allowed us to better predict civil society participation by understanding the possible effects of these two predictors. In future works we would work to expand beyond 2019. Working with multiple years would have allowed us to make broader generalizations about civil society participation due to the larger amount of data we could use for training. Additionally, it would have allowed us to see patterns in civil society over time and country that we were not able to see with just the 2019 data. These data were also limited in the sense that we were not able to make generalizations or predictions about regions/countries in general because we could only predict for 2019. This does not have much practical use considering 2019 is only one year. 

Also include a brief paragraph on what you would do differently if you were able to start over with the project.

If we were to start over with this project, we would take more time to develop our questions and analysis of the data, in addition to the training set limitations discussed in the prior paragraph. Going into the project, we did not have a strong understanding of the data we were working with. This  made formulating our question difficult. Doing some data exploration to learn about the realtionships between explanatory variables would have helped in formulating a question. From there, being more intentional about the data we used from the beginning would have been different, as well. In our data analysis phase, we ended up making a lot of decisions about data cleaning and data wrangling, even some about the basics of the project itself, that should have been made earlier. Choosing to focus on one year instead of multiple was a decision we do not regret, but coming to this choice at the beginning of the project would have greatly changed our data exploration and cleaning phases, as we had to approach them from a different perspective and basically redo them to do data analysis. Furthermore, learning more about the predictors themselves is a change we would make. We did not assess for covariance or any other sort of relationship between predictors. We also did not realize that some predictors we chose for our model would simply be NA for all observations, leading us to remove it later on. Additionally, the late inclusion or dropping of predictors, which proved to be tedious, would have been avoided had we taken more time to fully explore the data in the beginning. In summary, if we were to do this project again, we would do a more in-depth exploration of the data itself, think more carefully about the feasibility of our research question, then be more intentional about the data exploration and visualization we do. 